{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Settings\n",
    "\n",
    "Set `FAST_MODE = True` for faster inference on smaller GPUs (reduces quality but speeds up generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True for faster inference on smaller GPUs\n",
    "FAST_MODE = False  # Change to True for faster generation with lower quality\n",
    "\n",
    "# Fast mode settings\n",
    "if FAST_MODE:\n",
    "    FAST_NUM_DIFFUSION_STEPS = 20  # Reduced from 50\n",
    "    FAST_IMAGE_SIZE = 128  # Reduced from 256\n",
    "    FAST_NUM_SEEDS = 2  # Reduced number of images per grid\n",
    "else:\n",
    "    FAST_NUM_DIFFUSION_STEPS = 50\n",
    "    FAST_IMAGE_SIZE = 256\n",
    "    FAST_NUM_SEEDS = None  # Use all provided seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "\n",
    "import sys \n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pipeline_attend_and_excite import AttendAndExcitePipeline\n",
    "from config import RunConfig\n",
    "from run import run_on_prompt, get_indices_to_alter\n",
    "from utils import vis_utils\n",
    "from utils.ptp_utils import AttentionStore\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Model Weights (may take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5201c112add42c093d186935d23680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "NUM_DIFFUSION_STEPS = FAST_NUM_DIFFUSION_STEPS if FAST_MODE else 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "MAX_NUM_WORDS = 77\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "# stable = AttendAndExcitePipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
    "# Not enough memory for full precision model\n",
    "stable = AttendAndExcitePipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16).to(device)\n",
    "tokenizer = stable.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pipeline Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configurable parameters (see RunConfig for all parameters)\n",
    "# scale factor - intensity of shift by gradient\n",
    "# thresholds - a dictionary for iterative refinement mapping the iteration number to the attention threshold\n",
    "# max_iter_to_alter- maximal inference timestep to apply Attend-and-Excite\n",
    "def run_and_display(prompts: List[str],\n",
    "                    controller: AttentionStore,\n",
    "                    indices_to_alter: List[int],\n",
    "                    generator: torch.Generator,\n",
    "                    run_standard_sd: bool = False,\n",
    "                    scale_factor: int = 20,\n",
    "                    thresholds: Dict[int, float] = {0:0.05, 10: 0.5, 20: 0.8},\n",
    "                    max_iter_to_alter: int = 25,\n",
    "                    display_output: bool = False,\n",
    "                    sd_2_1: bool = False):\n",
    "    config = RunConfig(prompt=prompts[0],\n",
    "                       run_standard_sd=run_standard_sd,\n",
    "                       scale_factor=scale_factor,\n",
    "                       thresholds=thresholds,\n",
    "                       max_iter_to_alter=max_iter_to_alter,\n",
    "                       sd_2_1=sd_2_1)\n",
    "    image = run_on_prompt(model=stable,\n",
    "                          prompt=prompts,\n",
    "                          controller=controller,\n",
    "                          token_indices=indices_to_alter,\n",
    "                          seed=generator,\n",
    "                          config=config)\n",
    "    if display_output:\n",
    "        display(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run Inference on a Set of Seeds and Generate an Image Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images_for_method(prompt: str,\n",
    "                               seeds: List[int],\n",
    "                               indices_to_alter: Optional[List[int]] = None,\n",
    "                               is_attend_and_excite: bool = True,\n",
    "                               sd_2_1: bool = False):\n",
    "    token_indices = get_indices_to_alter(stable, prompt) if indices_to_alter is None else indices_to_alter\n",
    "    \n",
    "    # Use fewer seeds in fast mode\n",
    "    if FAST_MODE and FAST_NUM_SEEDS is not None:\n",
    "        seeds = seeds[:FAST_NUM_SEEDS]\n",
    "    \n",
    "    images = []\n",
    "    for seed in seeds:\n",
    "        g = torch.Generator('cuda').manual_seed(seed)\n",
    "        prompts = [prompt]\n",
    "        controller = AttentionStore()\n",
    "        run_standard_sd = False if is_attend_and_excite else True\n",
    "        image = run_and_display(prompts=prompts,\n",
    "                                controller=controller,\n",
    "                                indices_to_alter=token_indices,\n",
    "                                generator=g,\n",
    "                                run_standard_sd=run_standard_sd,\n",
    "                                sd_2_1=sd_2_1)\n",
    "        # Use smaller image size in fast mode\n",
    "        img_size = FAST_IMAGE_SIZE if FAST_MODE else 256\n",
    "        images.append(image.resize((img_size, img_size)))\n",
    "    grid = vis_utils.get_image_grid(images)\n",
    "    display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "# Stable Diffusion vs. Attend-and-Excite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "## Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'cat', 3: 'and', 4: 'a', 5: 'frog'}\n"
     ]
    }
   ],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a cat and a frog\",\n",
    "    seeds=[6141, 9031, 969, 1910],\n",
    "    is_attend_and_excite=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "## Attend-and-Excite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a cat and a frog\",\n",
    "    seeds=[6141, 9031, 969, 1910],\n",
    "    is_attend_and_excite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a mouse and a red car\",\n",
    "    seeds=[7803, 2098, 15792, 2354],\n",
    "    is_attend_and_excite=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Attend-and-Excite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a mouse and a red car\",\n",
    "    seeds=[7803, 2098, 15792, 2354],\n",
    "    is_attend_and_excite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIFFUSION_STEPS = FAST_NUM_DIFFUSION_STEPS if FAST_MODE else 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "MAX_NUM_WORDS = 77\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "stable = AttendAndExcitePipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\").to(device)\n",
    "tokenizer = stable.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a cat and a dog\",\n",
    "    seeds=[39, 63, 68, 62],\n",
    "    is_attend_and_excite=False,\n",
    "    sd_2_1=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_images_for_method(\n",
    "    prompt=\"a cat and a dog\",\n",
    "    seeds=[39, 63, 68, 62],\n",
    "    is_attend_and_excite=True,\n",
    "    sd_2_1=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
